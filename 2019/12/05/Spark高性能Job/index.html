<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="BigData," />










<meta name="description" content="Spark高性能Job">
<meta name="keywords" content="BigData">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark高性能Job">
<meta property="og:url" content="http://yoursite.com/2019/12/05/Spark高性能Job/index.html">
<meta property="og:site_name" content="JinZeng&#39;s Blog">
<meta property="og:description" content="Spark高性能Job">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/2019/12/05/Spark高性能Job/3958688-04c7a31cd515ed86.webp">
<meta property="og:image" content="http://yoursite.com/2019/12/05/Spark高性能Job/kuanyilai.webp">
<meta property="og:image" content="http://yoursite.com/2019/12/05/Spark高性能Job/shuffle.png">
<meta property="og:image" content="http://yoursite.com/2019/12/05/Spark高性能Job/shuffle111.png">
<meta property="og:image" content="http://yoursite.com/2019/12/05/Spark高性能Job/shuffle222.png">
<meta property="og:image" content="http://yoursite.com/2019/12/05/Spark高性能Job/shufflewrite.png">
<meta property="og:image" content="http://yoursite.com/2019/12/05/Spark高性能Job/s1.png">
<meta property="og:image" content="http://yoursite.com/2019/12/05/Spark高性能Job/g1.png">
<meta property="og:image" content="http://yoursite.com/2019/12/05/Spark高性能Job/s2.png">
<meta property="og:image" content="http://yoursite.com/2019/12/05/Spark高性能Job/111111111111111111111111.png">
<meta property="og:image" content="http://yoursite.com/2019/12/05/Spark高性能Job/1212.png">
<meta property="og:image" content="http://yoursite.com/2019/12/05/Spark高性能Job/123.png">
<meta property="og:image" content="http://yoursite.com/2019/12/05/Spark高性能Job/1234.png">
<meta property="og:updated_time" content="2019-12-05T13:56:54.973Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark高性能Job">
<meta name="twitter:description" content="Spark高性能Job">
<meta name="twitter:image" content="http://yoursite.com/2019/12/05/Spark高性能Job/3958688-04c7a31cd515ed86.webp">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/12/05/Spark高性能Job/"/>





  <title>Spark高性能Job | JinZeng's Blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">JinZeng's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">nlp</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/12/05/Spark高性能Job/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="JinZeng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JinZeng's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Spark高性能Job</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-12-05T21:36:55+08:00">
                2019-12-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/BigData/" itemprop="url" rel="index">
                    <span itemprop="name">BigData</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          
              <div class="post-description">
                  Spark高性能Job
              </div>
          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="Spark高性能Job"><a href="#Spark高性能Job" class="headerlink" title="Spark高性能Job"></a><center>Spark高性能Job<center></center></center></h1><h2 id="1-Spark基础概念"><a href="#1-Spark基础概念" class="headerlink" title="1 Spark基础概念"></a>1 Spark基础概念</h2><h3 id="1-1-Job"><a href="#1-1-Job" class="headerlink" title="1.1 Job"></a>1.1 Job</h3><p>遇到一个action算子就会提交一个job，常见的transformation算子以及Action算子：</p>
<ul>
<li>Transformation<ul>
<li>map, mapPartitions, flatMap, filter, union, groupbyKey, repartition, cache</li>
</ul>
</li>
<li>Action<ul>
<li>reduce, collect, show, count, foreach, save一系列操作</li>
</ul>
</li>
</ul>
<h3 id="1-2-Stage"><a href="#1-2-Stage" class="headerlink" title="1.2 Stage"></a>1.2 Stage</h3><p>​    一个job会有多个算子操作，这些算子都是将一个父RDD转为子RDD。<strong>如果父RDD的每个分区只被一个子RDD分区使用</strong>，那么就是窄依赖！如果<strong>父RDD的每个分区都有可能被多个子RDD分区使用，子RDD分区通常对应父RDD所有分区，那么就是宽依赖，如groupByKey。会通过一个Partitioner函数将父RDD中每个分区上key不同的记录分发到不同的子RDD分区</strong>。</p>
<ul>
<li><p>窄依赖</p>
<ul>
<li>包括map, filter, union, join(父RDD是hash-partitioned ), mapPartitions, mapValues</li>
</ul>
<p><img src="/2019/12/05/Spark高性能Job/3958688-04c7a31cd515ed86.webp" alt=""></p>
<p>​    </p>
</li>
<li><p>宽依赖</p>
<ul>
<li>包括groupByKey, join(父RDD不是hash-partitioned ), partitionBy</li>
</ul>
<p><img src="/2019/12/05/Spark高性能Job/kuanyilai.webp" alt=""></p>
</li>
</ul>
<p><strong>shuffle操作即宽依赖算子一般是任务中最耗时耗资源的部分。因为数据可能存放在HDFS不同的节点上，以一个stage的执行需要去拉取上一个stage的数据（shuffle read），保存在自己的节点上，会增加网络通信与IO。</strong></p>
<ul>
<li>宽依赖与窄依赖对比<ul>
<li>宽依赖往往对应者shuffle操作，在运行时会将<strong>同一个RDD分区传入到不同的子RDD分区中，中间涉及到多个节点的数据传输，非常耗时。</strong>而窄依赖的的每个父RDD分区通常只会传入到一个子RDD分区中，<strong>这个操作在一个机器节点就可以完成。</strong></li>
<li>宽依赖：需要所有的父分区都可用，必须等RDD的parent partition数据全部ready之后才能开始计算。</li>
</ul>
</li>
</ul>
<h3 id="1-3-Task"><a href="#1-3-Task" class="headerlink" title="1.3 Task"></a>1.3 Task</h3><p>​    task是spark最小的执行单元，<strong>task的数量就是stage的并行度，分配给不同的executor去执行</strong>。RDD在计算的时候，每个分区都会启一个task，这就是我们常说的<strong>数据并行！</strong>在map阶段，partition分区的数量保持不变，在reduce阶段，RDD聚合会触发shuffle操作。</p>
<h2 id="2-Spark-Shuffle"><a href="#2-Spark-Shuffle" class="headerlink" title="2 Spark Shuffle"></a>2 Spark Shuffle</h2><p>shuffle是spark job中一个比较重要的阶段，发生在map与reduce之间。</p>
<h3 id="2-1-举例分析"><a href="#2-1-举例分析" class="headerlink" title="2.1 举例分析"></a>2.1 举例分析</h3><p><img src="/2019/12/05/Spark高性能Job/shuffle.png" alt=""></p>
<p>对于上述的reduceByKey，<strong>涉及到需要将相同的key进行聚合。</strong>对于Stage1中的每个分区的数据，其输入可能存在于Stage0中的每个分区，<strong>因此需要从上游的每一个分区所在的机器拉取数据，这个过程称为shuffle。</strong></p>
<h3 id="2-2-Shuffle-Write"><a href="#2-2-Shuffle-Write" class="headerlink" title="2.2 Shuffle Write"></a>2.2 Shuffle Write</h3><p>shuffle write操作发生在ShuffleMapTask，Spark中的task分为以下两种类型：</p>
<ul>
<li>ShuffleMapTask<ul>
<li>负责rdd之间的transform，map的输出也就是shuffle write</li>
</ul>
</li>
<li>ResultTask<ul>
<li>job最后阶段的执行任务，也就是action操作。</li>
</ul>
</li>
</ul>
<h4 id="2-2-1-shuffle-write分析"><a href="#2-2-1-shuffle-write分析" class="headerlink" title="2.2.1 shuffle write分析"></a>2.2.1 shuffle write分析</h4><ul>
<li><p>Hash Based Shuffle</p>
<p><img src="/2019/12/05/Spark高性能Job/shuffle111.png" alt=""></p>
<p>​    上图有四个ShuffleMapTask，假设在这四个都在一个worker node上运行，CPU的核为2,可以同时运行2个task（一个核运行两个线程，<strong>可能是超线程技术</strong>）。</p>
<p>​    那么每个执行shuffle write的task，要为下一个stage创建多少个磁盘文件呢？很简单，下一个stage的task有多少个，当前stage的每个Map task就要创建多少份磁盘文件。比如下一个stage总共有100个task，那么当前stage的每个task都要创建100份磁盘文件。如果当前stage有50个task，总共有10个Executor，每个Executor执行5个Task，那么每个Executor上总共就要创建500个磁盘文件，所有Executor上会创建5000个磁盘文件。由此可见，未经优化的shuffle write操作所产生的磁盘文件的数量是极其惊人的。</p>
<p>​    <strong>每个task包含R个缓冲区，R=Reducer的个数（也就是下个stage中task的个数），缓冲区被称为bucket。</strong>在将数据写入磁盘之前，会先将数据写入内存缓冲中，当内存缓冲填满之后，才会溢写到磁盘文件中去</p>
<p>但上述可能会出现下面几个问题：</p>
<ul>
<li><p>本地磁盘根据bucket产生的blockfile很多，<strong>ShuffleMap task产生R个blockfile，M个ShuffleMapTask产生M×R个文件。</strong>一般Spark Job的M与R都很大，因此磁盘上会有大量的blockfile文件</p>
</li>
<li><p>缓冲区内存占用空间大</p>
<p>每个  ShuffleMapTask 需要开 R 个 bucket，M 个 ShuffleMapTask 就会产生 M * R 个 bucket。实际情况下，在一个worker node上，可以并行运行cores个ShuffleMapTask，一个机器上的bucket个数达到cores×R个，这会占用大量的内存空间。</p>
</li>
</ul>
<p>对于第二个问题，由于从内存往磁盘写数据一定得开缓冲区（内存与磁盘速度不匹配），所以对于第二个问题而言，没有较好的方法解决！但第一个问题可以通过下面的方法解决。</p>
</li>
<li><p>Consolidation机制的Shuffle</p>
<p><img src="/2019/12/05/Spark高性能Job/shuffle222.png" alt=""></p>
<p>​    在一个 core 上连续执行的 ShuffleMapTasks 可以共用一个输出文件 ShuffleFile。先执行完ShuffleMapTask 形成 ShuffleBlock i，后执行的 ShuffleMapTask 可以将输出数据直接追加到 ShuffleBlock i 后面，形成 ShuffleBlock i’，每个 ShuffleBlock 被称为 <strong>FileSegment</strong>。下一个 stage 的 reducer 只需要 fetch 整个 ShuffleFile 就行了。这样，每个 worker 持有的文件数降为 cores * R。</p>
<p>​    假设第二个stage有100个task，第一个stage有50个task，总共还是有10个Executor，每个Executor执行5个task。那么原本使用未经优化的HashShuffleManager时，每个Executor会产生500个磁盘文件，所有Executor会产生5000个磁盘文件的。但是此时经过优化之后，每个Executor创建的磁盘文件的数量的计算公式为：CPU core的数量 * 下一个stage的task数量。也就是说，每个Executor此时只会创建100个磁盘文件，所有Executor只会创建1000个磁盘文件。</p>
</li>
<li><p><strong>在map阶段，除了map的业务逻辑外，还有shuffle write的过程，这个过程涉及到序列化、磁盘IO等耗时操作；在reduce阶段，除了reduce的业务逻辑外，还有前面shuffle read过程，这个过程涉及到网络IO、反序列化等耗时操作。</strong></p>
</li>
</ul>
<h3 id="2-3-Shuffle-Read"><a href="#2-3-Shuffle-Read" class="headerlink" title="2.3 Shuffle Read"></a>2.3 Shuffle Read</h3><p><img src="/2019/12/05/Spark高性能Job/shufflewrite.png" alt=""></p>
<ul>
<li><strong>前一个stage的ShuffleMapTask进行shuffle write，把数据存储在blockManager中，并且把数据位置元信息上报到driver的mapOutTrack组件，下一个stage根据数据位置元信息，进行shuffle read，拉取上一个stage的输出数据。</strong></li>
<li><strong>shuffle read实际是从上游executor以block为单位获取数据。当数据分布均匀的时候，导致下游某个partition过大。即上游某个block太大，就会出现OOM。</strong></li>
</ul>
<h4 id="2-3-1-shuffle-read分析"><a href="#2-3-1-shuffle-read分析" class="headerlink" title="2.3.1 shuffle read分析"></a>2.3.1 shuffle read分析</h4><p><img src="/2019/12/05/Spark高性能Job/s1.png" alt=""></p>
<p>​    执行shuffle read时，要将数据从MapPartitionsRDD 中的数据 fetch 过来。有一个问题？Reducer怎么知道应该去哪里找需要fetch的数据？答案是：<strong>在进行shuffle write的时候，会把数据位置元信息上报到driver的mapOutTrack组件，下一个stage根据数据位置元信息，进行shuffle read，拉取上一个stage的输出数据。</strong></p>
<h3 id="2-4-transform算子对应的shuffle-read举例"><a href="#2-4-transform算子对应的shuffle-read举例" class="headerlink" title="2.4 transform算子对应的shuffle read举例"></a>2.4 transform算子对应的shuffle read举例</h3><ul>
<li><p>reduceByKey</p>
<p>reduceByKey是在fetch的同时进行reduce操作。方式是类似于Spark中<strong>aggregateByKey的方式</strong>，fetch来的数据设置一种数据结构比如HashMap，方便aggregate。reduce阶段fetch来的数据被逐个aggreagte到HashMap中，<strong>等所有记录都进入到了HashMap即完成了Reduce任务。</strong>注意，在reduce前的map阶段，Spark需要很多小buffer来存储bucket到磁盘！</p>
</li>
<li><p>groupByKey</p>
</li>
<li><p>distinct</p>
</li>
<li><p>cogroup</p>
</li>
<li><p>intersection(otherRDD)</p>
</li>
<li><p>join(otherRDD, numPartitions)</p>
</li>
<li><p>sortByKey</p>
</li>
</ul>
<h3 id="2-5-Shuffle-Read中的HashMap"><a href="#2-5-Shuffle-Read中的HashMap" class="headerlink" title="2.5 Shuffle Read中的HashMap"></a>2.5 Shuffle Read中的HashMap</h3><p>HashMap是Spark Shuffle read过程中频繁使用的、用于<strong>aggregate 的数据结构</strong>。Spark 设计了两种：一种是全内存的 AppendOnlyMap，另一种是内存＋磁盘的 ExternalAppendOnlyMap。（参考链接：<a href="https://cloud.tencent.com/developer/article/1085719解释的非常详细）" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1085719解释的非常详细）</a></p>
<h2 id="3-性能优化"><a href="#3-性能优化" class="headerlink" title="3 性能优化"></a>3 性能优化</h2><h3 id="3-1-对多次使用的RDD进行持久化"><a href="#3-1-对多次使用的RDD进行持久化" class="headerlink" title="3.1 对多次使用的RDD进行持久化"></a>3.1 对多次使用的RDD进行持久化</h3><h3 id="3-2-进来避免使用shuffle算子"><a href="#3-2-进来避免使用shuffle算子" class="headerlink" title="3.2 进来避免使用shuffle算子"></a>3.2 进来避免使用shuffle算子</h3><ul>
<li>shuffle过程中，各个节点上的相同key都会先写入本地磁盘文件中（也就是我们的<strong>blockfile</strong>），然后其他节点需要通过网络传输拉取各个节点上的磁盘文件中的相同key。而且相同key都拉取到同一个节点进行聚合操作时，还有可能会因为一个节点上处理的key过多，导致内存不够存放，进而溢写到磁盘文件中。因此在shuffle过程中，可能会发生大量的磁盘文件读写的IO操作，以及数据的网络传输操作。</li>
<li>常见的shuffle算子有<strong>reduceByKey、join、distinct、repartition</strong></li>
</ul>
<h4 id="3-2-1-举例：使用BroadCast与map来代替join算子"><a href="#3-2-1-举例：使用BroadCast与map来代替join算子" class="headerlink" title="3.2.1 举例：使用BroadCast与map来代替join算子"></a>3.2.1 举例：使用BroadCast与map来代替join算子</h4><p>​    传统的join操作会导致shuffle操作，为什么？不同父RDD中相同的key会通过网络拉取到一个节点上，也就是我们的<strong>宽依赖操作</strong>。<strong>然后由该节点上的一个task进行join操作。</strong></p>
<p>改进：</p>
<p>将<strong>数据量较小的RDD作为广播变量</strong>发到每个工作节点，然后在执行join。在rdd1.map中，可以从rdd2DataBroadcast中，获取rdd2的所有数据。然后遍历rdd2的所有数据，若发现某条记录的key与rdd1中当前数据的key相同，则进行join（<strong>或者使用rdd2DataBroadcast来与rdd1进行join</strong>）。需要注意的是，上述操作，仅仅在<strong>rdd2较小（几百兆或者1G）下使用，因为在每个Executor的内存中，都会驻留一份rdd2的全量数据。</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val rdd2Data = rdd2.collect()</span><br><span class="line">val rdd2DataBroadcast = sc.broadcast(rdd2Data)</span><br><span class="line">val rdd3 = rdd1.map(rdd2DataBroadcast...)</span><br></pre></td></tr></table></figure>
<h3 id="3-3-使用map-side预聚合的shuffle算子"><a href="#3-3-使用map-side预聚合的shuffle算子" class="headerlink" title="3.3 使用map-side预聚合的shuffle算子"></a>3.3 使用map-side预聚合的shuffle算子</h3><ul>
<li><p>map-side预聚合</p>
<ul>
<li>在每个节点本地对相同的key进行一次聚合操作，<strong>类似于MapReduce中的本地combiner</strong>。map-side预聚合后，<strong>每个节点本地只会有一条相同的key，因为多于相同的key都被聚合起来了。</strong>reducer在拉取所有节点上相同的key时，就会大大减少拉取的数据数量。</li>
<li>即<strong>尽量使用reduceByKey或者aggregateByKey算子来替代掉groupByKey算子</strong>。因为reduceByKey和aggregateByKey算子<strong>会使用用户自定义函数对每个节点本地相同的key进行预聚合</strong>。而groupByKey算子是不会进行预聚合的，全量的数据会在集群的各个节点之间分发和传输，性能相对来说比较差。</li>
</ul>
<p>groupByKey算子示例：</p>
<p><img src="/2019/12/05/Spark高性能Job/g1.png" alt=""></p>
<p>reduceByKey算子示例：</p>
<p><img src="/2019/12/05/Spark高性能Job/s2.png" alt=""></p>
</li>
</ul>
<h3 id="3-4-使用高性能算子"><a href="#3-4-使用高性能算子" class="headerlink" title="3.4 使用高性能算子"></a>3.4 使用高性能算子</h3><ul>
<li>使用mapPartitions代替普通map<ul>
<li>一次函数调用会处理一个partition所有的数据，而不是一次函数调用处理一条。<strong>但是单次函数调用就要处理掉一个partition所有的数据，如果内存不够，很可能出现OOM异常</strong></li>
</ul>
</li>
</ul>
<h3 id="3-5-广播大变量"><a href="#3-5-广播大变量" class="headerlink" title="3.5 广播大变量"></a>3.5 广播大变量</h3><ul>
<li><p><strong>当算子函数使用外部变量时，</strong>默认情况下，Spark会将该变量复制多个副本，通过网络传输到task中，<strong>每个task都会保留一份变量副本</strong>。如果变量本身较大，那么大量的变量副本在网络传输中非常消耗性能（有多少个task就要传递多少个变量副本）。</p>
<p>解决方法：</p>
<p>​    使用Spark广播。<strong>广播后的变量，会保证每个Executor的内存中，只驻留一份变量副本，而Executor中的task执行时共享该Executor中的那份变量副本</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">// 以下代码在算子函数中，使用了外部的变量。</span><br><span class="line">// 此时没有做任何特殊操作，每个task都会有一份list1的副本。</span><br><span class="line">val list1 = ...</span><br><span class="line">rdd1.map(list1...)</span><br><span class="line"></span><br><span class="line">// 以下代码将list1封装成了Broadcast类型的广播变量。</span><br><span class="line">// 在算子函数中，使用广播变量时，首先会判断当前task所在Executor内存中，是否有变量副本。</span><br><span class="line">// 如果有则直接使用；如果没有则从Driver或者其他Executor节点上远程拉取一份放到本地Executor内存中。</span><br><span class="line">// 每个Executor内存中，就只会驻留一份广播变量副本。</span><br><span class="line">val list1 = ...</span><br><span class="line">val list1Broadcast = sc.broadcast(list1)</span><br><span class="line">rdd1.map(list1Broadcast...)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="3-6-spark-submit的参数设置"><a href="#3-6-spark-submit的参数设置" class="headerlink" title="3.6 spark-submit的参数设置"></a>3.6 spark-submit的参数设置</h3><p><img src="/2019/12/05/Spark高性能Job/111111111111111111111111.png" alt=""></p>
<ul>
<li>使用spark-submit提交作业，该作业会启动一个对应的Driver进程。根据部署模式的不同，Driver进程可能会在本地启动（local模式），或者集群中某一节点启动（yarn模式）。</li>
<li>Driver向Yarn集群管理器申请运行Spark作业的资源，这里的资源指的是<strong>Executor进程</strong>。Yarn会根据Spark作业设置的参数，在各个工作节点上，启动一定数量的<strong>Executor进程，每个进程都占有一定数量的内存以及cpu core</strong></li>
<li>申请好作业执行资源后，Driver进程会调度执行作业代码！首先，Driver进程将作业分成多个stage，并为每个stage创建一批task，<strong>然后将各个task分配到各个Executor中执行（在Executor中执行的每个task可以想象为线程）</strong>。当一个stage执行结束，<strong>会在各个节点本地进行shuffle write，写入中间计算结果</strong>。然后Driver开始调度执行下一个stage。</li>
<li>当我们在代码中执行了cache/persist等持久化操作时，根据我们选择的持久化级别的不同，每个task计算出来的数据也会保存到Executor进程的内存或者所在节点的磁盘文件中</li>
</ul>
<p>task的执行速度是跟每个Executor进程的CPU core数量有直接关系的。<strong>一个cpu core同一时间只能执行一个线程，而每个Executor进程上分配得到的多个task，多是以多个线程并发运行的。（多个线程抢占Executor的CPU core运行）</strong>。如果Executor上的cpu core &lt;&lt; task数量，那么每个cpu core会轮询task，有些task会被抢占等待资源，使得作业变慢。</p>
<ul>
<li><p>num-executors</p>
<ul>
<li>设置太少或太多的Executor进程都不好。设置的太少，无法充分利用集群资源；设置的太多的话，大部分队列可能无法给予充分的资源。</li>
</ul>
</li>
<li><p>executor-memory</p>
<ul>
<li>如果每个executor的内存太小，可能会出现OOM</li>
</ul>
</li>
<li><p>executor-cores</p>
<ul>
<li>这个参数决定了每个Executor进程并行执行task线程的能力。因为每个CPU core同一时间只能执行一个task线程，因此每个Executor进程的CPU core数量越多，越能够快速地执行完分配给自己的所有task线程</li>
</ul>
</li>
<li><p>spark.default.parallelism</p>
<ul>
<li>设置stage默认的task数量</li>
<li><strong>该参数非常重要，会影响到总的task数量。如果task数量偏少的话，就会导致你前面设置好的Executor的参数都前功尽弃</strong>。因为，无论你的Executor进程有多少个，内存与CPU有多大，但是如果task总量少，Executor进程的资源无法得到充分使用！建议：<strong>设置该参数为num-executors * executor-cores的2~3倍较为合适，比如Executor的总CPU core数量为300个，那么设置1000个task是可以的，此时可以充分地利用Spark集群的资源</strong>。</li>
</ul>
</li>
<li><p>spark.storage.memoryFraction</p>
<ul>
<li>Executor的内存分配<ul>
<li><strong>第一块是让task执行我们自己编写的代码时使用，默认是占Executor总内存的20%；第二块是让task通过shuffle过程拉取了上一个stage的task的输出后，进行聚合等操作时使用，默认也是占Executor总内存的20%；第三块是让RDD持久化时使用，默认占Executor总内存的60%</strong></li>
</ul>
</li>
<li>该参数在作业中有持久化RDD的时候才需要设置。</li>
</ul>
</li>
<li><p>spark.shuffle.memoryFraction</p>
<ul>
<li><p>该参数设置shuffle过程中，一个task拉取到上一个stage的task输出后，进行reduce的时候使用的Executor内存的比例。当设置为0.2，Executor默认只有20%的内存来进行该操作。shuffle操作在进行聚合时，如果发现使用的内存超出了这个20%的限制，那么多余的数据就会溢写到磁盘文件中去，此时就会极大地降低性能。</p>
</li>
<li><p>设置的建议：</p>
<p>如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，提高shuffle操作的内存占比比例，避免shuffle过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能</p>
</li>
</ul>
</li>
</ul>
<h2 id="4-性能优化高阶—-数据倾斜"><a href="#4-性能优化高阶—-数据倾斜" class="headerlink" title="4 性能优化高阶—-数据倾斜"></a>4 性能优化高阶—-数据倾斜</h2><h3 id="4-1什么是数据倾斜"><a href="#4-1什么是数据倾斜" class="headerlink" title="4.1什么是数据倾斜"></a>4.1什么是数据倾斜</h3><p>​    在进行shuffle操作的时候，将各个节点上相同的key拉取到某个节点上的task来执行（shuffle read阶段）。<strong>如果某个key对应的数据量非常大，就会发生数据倾斜。</strong>比如，大部分key对应只有10条数据，但个别key有100万，那么大部分task可能只会分配到10条数据（<strong>这是reduce阶段决定的，相同的key发往同一个task进行reduce</strong>），然后1秒运行结束。但个别task会分配超过100万数据，所以要运行很久。</p>
<p><img src="/2019/12/05/Spark高性能Job/1212.png" alt=""></p>
<p>如图所示，在reduce对应的task中，处理hello的task线程处理的数据量很大，需要很长时间的运行。</p>
<h3 id="4-2-可能会发生数据倾斜的算子"><a href="#4-2-可能会发生数据倾斜的算子" class="headerlink" title="4.2 可能会发生数据倾斜的算子"></a>4.2 可能会发生数据倾斜的算子</h3><p>数据倾斜会发生在shuffle过程中，一下算子可能会触发shuffle：distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition</p>
<h4 id="4-2-1-某个task执行非常慢的情况"><a href="#4-2-1-某个task执行非常慢的情况" class="headerlink" title="4.2.1 某个task执行非常慢的情况"></a>4.2.1 某个task执行非常慢的情况</h4><p>​    某个task执行非常慢的情况：<strong>查看作业当前运行的stage下每个task分配的数据量</strong></p>
<p>​    在Web UI上可以看到<strong>每个stage</strong>各个task的分配数据量大小，从而进一步确定是不是task分配的数据不均匀导致。（在Web UI stage栏目可以看到<strong>每个stage下并行的task分配的数据量</strong>）如果不出意外：会看到<strong>有的task运行非常快，几秒钟; 有的task运行非常慢，仅仅从时间上已经能看出数据倾斜了！</strong>在通过查看每个task处理的数据量，可以看到处理的数据量也有很大的区别。在知道是哪个stage发生了数据倾斜之后，根据stage的划分原理。推算到Spark作业中对应哪行代码有问题！</p>
<h4 id="4-2-2-某个task出现莫名其妙的内存溢出"><a href="#4-2-2-某个task出现莫名其妙的内存溢出" class="headerlink" title="4.2.2 某个task出现莫名其妙的内存溢出"></a>4.2.2 某个task出现莫名其妙的内存溢出</h4><p>通过Web UI使用相同的方法查看</p>
<h4 id="4-2-3-查看导致数据倾斜的key的数据分布情况"><a href="#4-2-3-查看导致数据倾斜的key的数据分布情况" class="headerlink" title="4.2.3 查看导致数据倾斜的key的数据分布情况"></a>4.2.3 查看导致数据倾斜的key的数据分布情况</h4><p>​    通过RDD的<strong>countByKey</strong>，查看RDD中不同key的数据量分布。然后对统计出来的各个key出现的次数，collect/take到客户端打印一下，就可以看到key的分布情况。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val sampledPairs = pairs.sample(false, 0.1)</span><br><span class="line">val sampledWordCounts = sampledPairs.countByKey()</span><br><span class="line">sampledWordCounts.foreach(println(_))</span><br></pre></td></tr></table></figure>
<h3 id="4-3-数据倾斜的解决方案"><a href="#4-3-数据倾斜的解决方案" class="headerlink" title="4.3 数据倾斜的解决方案"></a>4.3 数据倾斜的解决方案</h3><h4 id="4-3-1-使用Hive-ETL预处理数据"><a href="#4-3-1-使用Hive-ETL预处理数据" class="headerlink" title="4.3.1 使用Hive ETL预处理数据"></a>4.3.1 使用Hive ETL预处理数据</h4><h4 id="4-3-2-过滤少数倾斜的key"><a href="#4-3-2-过滤少数倾斜的key" class="headerlink" title="4.3.2 过滤少数倾斜的key"></a>4.3.2 过滤少数倾斜的key</h4><p>​    如果发现导致倾斜的key就少数几个，而且对计算本身的影响并不大的话，那么很适合使用这种方案。比如99%的key就对应10条数据，但是只有一个key对应了100万数据，从而导致了数据倾斜。</p>
<p>​    实际操作：<strong>采取每次执行前先进行采样，计算出样本中数据量最大的几个key之后，直接在程序中将那些key给过滤掉。</strong></p>
<h4 id="4-3-3-提高shuffle操作的并行度"><a href="#4-3-3-提高shuffle操作的并行度" class="headerlink" title="4.3.3 提高shuffle操作的并行度"></a>4.3.3 提高shuffle操作的并行度</h4><p>​    在对RDD进行shuffle算子时，给shuffle算子传入一个参数，比如reduceByKey(1000)，该参数设置了shuffle算子执行时<strong>shuffle read task的数量</strong>。</p>
<p>​    原理：让原本分配给一个task的多个keu分配多个task，<strong>从而让每个task处理比原来更少的数据。</strong>缺点：无法应对极端情况，比如某个key对应的数据量有100万，那么无论你的task数量增加到多少，这个对应着100万数据的key肯定还是会分配到一个task中去处理，因此注定还是会发生数据倾斜的。</p>
<h4 id="4-3-4-两阶段聚合（局部聚合和全局聚合）"><a href="#4-3-4-两阶段聚合（局部聚合和全局聚合）" class="headerlink" title="4.3.4 两阶段聚合（局部聚合和全局聚合）"></a>4.3.4 两阶段聚合（局部聚合和全局聚合）</h4><p>​    对RDD执行reduceByKey等<strong>聚合类shuffle</strong>算子时使用。第一阶段聚合，先给每个key都打上一个随机数，此时原来的key就不同了。比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)，就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据，执行reduceByKey等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。然后将各个key的前缀给去掉，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)。</p>
<p>​    原理：<strong>将原本相同的key通过附加随机前缀的方式，变成多个不同的key，就可以让原本被一个task处理的数据分散到多个task上去做局部聚合，进而解决单个task处理数据量过多的问题</strong></p>
<p>​    方案缺点：仅仅适用于聚合类的shuffle操作，适用范围相对较窄。如果是join类的shuffle操作，还得用其他的解决方案</p>
<p><img src="/2019/12/05/Spark高性能Job/123.png" alt=""></p>
<h4 id="4-3-5-将reduce-join改为map-join"><a href="#4-3-5-将reduce-join改为map-join" class="headerlink" title="4.3.5 将reduce join改为map join"></a>4.3.5 将reduce join改为map join</h4><p>​    非常厉害的一个思路！！！！！！！！！！！！！！！！！！！！</p>
<p>​    使用场景：进行join的两个RDD，<strong>其中一个RDD或表的数据量比较小（比如几百M或者一两G）</strong></p>
<p>​    <strong>思路：Broadcast变量与map类算子实现join操作，进而完全规避掉shuffle类的操作，彻底避免数据倾斜的发生和出现。将较小RDD中的数据直接通过collect算子拉取到Driver端的内存中来，然后对其创建一个Broadcast变量；接着对另外一个RDD执行map类算子，在算子函数内，从Broadcast变量中获取较小RDD的全量数据，与当前RDD的每一条数据按照连接key进行比对，如果连接key相同的话，那么就将两个RDD的数据用你需要的方式连接起来。</strong></p>
<p>​    优点：对join操作导致的数据倾斜，效果非常好，因为根本就不会发生shuffle，也就根本不会发生数据倾斜</p>
<p>​    缺点：适用场景较少，因为这个方案只适用于一个大表和一个小表的情况。</p>
<h4 id="4-3-4-采样倾斜key并分拆join操作"><a href="#4-3-4-采样倾斜key并分拆join操作" class="headerlink" title="4.3.4 采样倾斜key并分拆join操作"></a>4.3.4 采样倾斜key并分拆join操作</h4><p>​    使用场景：当join的两张表都很大，无法使用上面的方案！如果出现数据倾斜，是因为其中某一个RDD/Hive表中的少数几个key的数据量过大，<strong>而另一个RDD/Hive表中的所有key都分布比较均匀</strong>，那么采用这个解决方案是比较合适的。</p>
<p>​    缺点：如果导致倾斜的key特别多的话，比如成千上万个key都导致数据倾斜，那么这种方式也不适合。</p>
<p><img src="/2019/12/05/Spark高性能Job/1234.png" alt=""></p>
<h3 id="4-4-Spark-Shuffle的多种机制"><a href="#4-4-Spark-Shuffle的多种机制" class="headerlink" title="4.4 Spark Shuffle的多种机制"></a>4.4 Spark Shuffle的多种机制</h3><ul>
<li>未经优化的HashShuffleManager</li>
<li>consolidate机制的HashShuffleManager</li>
<li><p>SortShuffleManager</p>
<ul>
<li>普通运行机制</li>
<li>bypass机制</li>
</ul>
</li>
<li><p>spark.shuffle.maneger</p>
<p>默认值是sort，该参数用于设置ShuffleManager的类型</p>
</li>
<li><p>spark.shuffle.consolidateFiles</p>
<p>默认值false，如果使用HashShuffleManager，该参数有效。如果设置为true，那么就会开启consolidate机制，会大幅度合并shuffle write的输出文件，对于shuffle read task数量特别多的情况下，这种方法可以极大地减少磁盘IO开销，提升性能。</p>
</li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/BigData/" rel="tag"># BigData</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/12/01/Zookeeper/" rel="next" title="Zookeeper解析">
                <i class="fa fa-chevron-left"></i> Zookeeper解析
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">JinZeng</p>
              <p class="site-description motion-element" itemprop="description">nlper</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">44</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">17</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">17</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://www.zhihu.com/people/jin-ge-ge-21-50-31/activities" target="_blank" title="zhihu">
                      
                        <i class="fa fa-fw fa-globe"></i>zhihu</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Spark高性能Job"><span class="nav-number">1.</span> <span class="nav-text">Spark高性能Job</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Spark基础概念"><span class="nav-number">1.1.</span> <span class="nav-text">1 Spark基础概念</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-Job"><span class="nav-number">1.1.1.</span> <span class="nav-text">1.1 Job</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-Stage"><span class="nav-number">1.1.2.</span> <span class="nav-text">1.2 Stage</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-Task"><span class="nav-number">1.1.3.</span> <span class="nav-text">1.3 Task</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Spark-Shuffle"><span class="nav-number">1.2.</span> <span class="nav-text">2 Spark Shuffle</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-举例分析"><span class="nav-number">1.2.1.</span> <span class="nav-text">2.1 举例分析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-Shuffle-Write"><span class="nav-number">1.2.2.</span> <span class="nav-text">2.2 Shuffle Write</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-1-shuffle-write分析"><span class="nav-number">1.2.2.1.</span> <span class="nav-text">2.2.1 shuffle write分析</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-Shuffle-Read"><span class="nav-number">1.2.3.</span> <span class="nav-text">2.3 Shuffle Read</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-1-shuffle-read分析"><span class="nav-number">1.2.3.1.</span> <span class="nav-text">2.3.1 shuffle read分析</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-transform算子对应的shuffle-read举例"><span class="nav-number">1.2.4.</span> <span class="nav-text">2.4 transform算子对应的shuffle read举例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-5-Shuffle-Read中的HashMap"><span class="nav-number">1.2.5.</span> <span class="nav-text">2.5 Shuffle Read中的HashMap</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-性能优化"><span class="nav-number">1.3.</span> <span class="nav-text">3 性能优化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-对多次使用的RDD进行持久化"><span class="nav-number">1.3.1.</span> <span class="nav-text">3.1 对多次使用的RDD进行持久化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-进来避免使用shuffle算子"><span class="nav-number">1.3.2.</span> <span class="nav-text">3.2 进来避免使用shuffle算子</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-1-举例：使用BroadCast与map来代替join算子"><span class="nav-number">1.3.2.1.</span> <span class="nav-text">3.2.1 举例：使用BroadCast与map来代替join算子</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-使用map-side预聚合的shuffle算子"><span class="nav-number">1.3.3.</span> <span class="nav-text">3.3 使用map-side预聚合的shuffle算子</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-使用高性能算子"><span class="nav-number">1.3.4.</span> <span class="nav-text">3.4 使用高性能算子</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-5-广播大变量"><span class="nav-number">1.3.5.</span> <span class="nav-text">3.5 广播大变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-6-spark-submit的参数设置"><span class="nav-number">1.3.6.</span> <span class="nav-text">3.6 spark-submit的参数设置</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-性能优化高阶—-数据倾斜"><span class="nav-number">1.4.</span> <span class="nav-text">4 性能优化高阶—-数据倾斜</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1什么是数据倾斜"><span class="nav-number">1.4.1.</span> <span class="nav-text">4.1什么是数据倾斜</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-可能会发生数据倾斜的算子"><span class="nav-number">1.4.2.</span> <span class="nav-text">4.2 可能会发生数据倾斜的算子</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-1-某个task执行非常慢的情况"><span class="nav-number">1.4.2.1.</span> <span class="nav-text">4.2.1 某个task执行非常慢的情况</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-2-某个task出现莫名其妙的内存溢出"><span class="nav-number">1.4.2.2.</span> <span class="nav-text">4.2.2 某个task出现莫名其妙的内存溢出</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-3-查看导致数据倾斜的key的数据分布情况"><span class="nav-number">1.4.2.3.</span> <span class="nav-text">4.2.3 查看导致数据倾斜的key的数据分布情况</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-数据倾斜的解决方案"><span class="nav-number">1.4.3.</span> <span class="nav-text">4.3 数据倾斜的解决方案</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-1-使用Hive-ETL预处理数据"><span class="nav-number">1.4.3.1.</span> <span class="nav-text">4.3.1 使用Hive ETL预处理数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-2-过滤少数倾斜的key"><span class="nav-number">1.4.3.2.</span> <span class="nav-text">4.3.2 过滤少数倾斜的key</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-3-提高shuffle操作的并行度"><span class="nav-number">1.4.3.3.</span> <span class="nav-text">4.3.3 提高shuffle操作的并行度</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-4-两阶段聚合（局部聚合和全局聚合）"><span class="nav-number">1.4.3.4.</span> <span class="nav-text">4.3.4 两阶段聚合（局部聚合和全局聚合）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-5-将reduce-join改为map-join"><span class="nav-number">1.4.3.5.</span> <span class="nav-text">4.3.5 将reduce join改为map join</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-4-采样倾斜key并分拆join操作"><span class="nav-number">1.4.3.6.</span> <span class="nav-text">4.3.4 采样倾斜key并分拆join操作</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-Spark-Shuffle的多种机制"><span class="nav-number">1.4.4.</span> <span class="nav-text">4.4 Spark Shuffle的多种机制</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">JinZeng</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
