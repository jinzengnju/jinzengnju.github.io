<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Tensorflow," />










<meta name="description" content="Tensorflow编程遇到的问题">
<meta name="keywords" content="Tensorflow">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensorflow编程遇到的问题">
<meta property="og:url" content="http://yoursite.com/2018/11/08/Tensorflow编程遇到的问题/index.html">
<meta property="og:site_name" content="JinZeng&#39;s Blog">
<meta property="og:description" content="Tensorflow编程遇到的问题">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/2018/11/08/Tensorflow编程遇到的问题/汉明.png">
<meta property="og:updated_time" content="2019-01-02T03:12:56.315Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Tensorflow编程遇到的问题">
<meta name="twitter:description" content="Tensorflow编程遇到的问题">
<meta name="twitter:image" content="http://yoursite.com/2018/11/08/Tensorflow编程遇到的问题/汉明.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/11/08/Tensorflow编程遇到的问题/"/>





  <title>Tensorflow编程遇到的问题 | JinZeng's Blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">JinZeng's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">nlp</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/08/Tensorflow编程遇到的问题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="JinZeng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JinZeng's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Tensorflow编程遇到的问题</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-08T21:23:25+08:00">
                2018-11-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Tensorflow/" itemprop="url" rel="index">
                    <span itemprop="name">Tensorflow</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          
              <div class="post-description">
                  Tensorflow编程遇到的问题
              </div>
          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="Tensorflow编程bug"><a href="#Tensorflow编程bug" class="headerlink" title="Tensorflow编程bug"></a><center>Tensorflow编程bug</center></h1><ul>
<li><p>执行sess.run(某tensor)或者某tensor.eval()函数的时候，已知卡住，也不报错。<strong>注意输入数据采用多线程的方法</strong></p>
<p>相关代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    model =create_model(sess,FLAGS)</span><br><span class="line">    coord=tf.train.Coordinator()</span><br><span class="line">    threads=tf.train.start_queue_runners(coord=coord)</span><br><span class="line">    <span class="keyword">with</span> tf.device(<span class="string">'/cpu:0'</span>):</span><br><span class="line">        fact_batch_words,batch_laws=inputs(FLAGS.data_dir,FLAGS.batch_size,vocab_dict)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        step=<span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> coord.should_stop():</span><br><span class="line">            start_time=time.time()</span><br><span class="line">            _, loss, accuracy = model.step(sess, fact_batch_words, batch_laws, dropout=FLAGS.dropout,forward_only=<span class="keyword">False</span>,sampling=<span class="keyword">False</span>)</span><br><span class="line">        time_use=time.time()-start_time</span><br><span class="line">        <span class="keyword">if</span> step%<span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'Step %d:loss=%.2f(%.3sec)'</span>%(step,loss,time_use))</span><br><span class="line">        step+=<span class="number">1</span></span><br><span class="line">    <span class="keyword">except</span> tf.errors.OutOfRangeError:</span><br><span class="line">        print(<span class="string">'Done training for %d epoches,%d steps'</span>%(FLAGS.num_epoches,step))</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        coord.request_stop()</span><br><span class="line">    coord.join(threads)</span><br><span class="line">    sess.close()</span><br></pre></td></tr></table></figure>
<p>问题发现：创建队列的线程在with tf.device中声明，而我们启动线程队列的命令在前面，那你后面当然拿不到数据了。所以我们应该将inputs()函数定义在启动线程队列之前。</p>
<p>对于同时新建图和会话，并在一个函数下定义一个图的结构以及会话session的执行，可以用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Graph().as_default(),tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  接下来就可以写相关的代码了。</span><br></pre></td></tr></table></figure>
<p>除此之外，我们解释一下这个函数在哪定义计算图的。请看下文：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model =create_model(sess,FLAGS)</span><br></pre></td></tr></table></figure>
<p>这个函数会创建一个Model对象，而创建Model对象时会执行构造函数<strong>init</strong>()，而我们的<strong>计算流图就是在这个构造函数中定义的。</strong>在创建了Model过后，会根据是否有ckpt文件，而选择从model文件中恢复，或者新建一个Model。但是，如果是新建一个Model，需要执行sess.run(tf.initialize_all_variables())函数进行初始化。</p>
</li>
<li><p>Coordinator线程协调器的作用</p>
<p><a href="https://blog.csdn.net/DaVinciL/article/details/77342027" target="_blank" rel="noopener">https://blog.csdn.net/DaVinciL/article/details/77342027</a></p>
<p>用来管理session中的多个线程，<strong>可以用来同时停止多个工作线程并且向那个在等待所有工作线程终止的程序报告异常，该程序在捕获到异常后就会终止所有线程。</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">try:</span><br><span class="line">        while not coord.should_stop():</span><br><span class="line">            print &apos;************&apos;</span><br><span class="line">            # 获取每一个batch中batch_size个样本和标签</span><br><span class="line">            image_batch_v, label_batch_v = sess.run([image_batch, label_batch])</span><br><span class="line">            print(image_batch_v.shape, label_batch_v)</span><br><span class="line">    except tf.errors.OutOfRangeError:  #如果读取到文件队列末尾会抛出此异常</span><br><span class="line">        print(&quot;done! now lets kill all the threads……&quot;)</span><br><span class="line">    finally:</span><br><span class="line">        # 协调器coord发出所有线程终止信号</span><br><span class="line">        coord.request_stop()</span><br><span class="line">        print(&apos;all threads are asked to stop!&apos;)</span><br><span class="line">    coord.join(threads) #把开启的线程加入主线程，等待threads结束</span><br><span class="line">    print(&apos;all threads are stopped!&apos;)</span><br></pre></td></tr></table></figure>
<p>当线程一直在运行，直到抛出抛出OutOfRangeError的时候，会请求线程停止coord.request_stop()，然后等着停止即可。<strong>那么有同学会问，为什么要设置while not coord.should_stop()</strong>，那是因为我们需要循环取batch的数据，如果不加这个循环条件，无法做到循环的获取batch的数据。</p>
<p>tf.Coordinator主要用于协同多个线程一起停止，并提供了should_stop、request_stop、join三个函数。在起订线程之前，需要先声明一个tf.Coordinator类，并将这个类传入每一个创建的线程中。启动的线程需要一直查询tf.Coordinator类中提供的should_stop函数，当这个函数的返回值为True时，则当前线程也需要退出。每一个启动的线程都可以通过调用request_stop函数来通知其他线程退出。当某一个线程调用request_stop函数之后should_stop函数的返回值将会被设置为True，这样其他的线程就可以同时停止了。</p>
</li>
<li><p>TypeError:feed cannot be a tf.Tensor object.Acceptable feed values include python scalars,strings,lists,or numpy ndarrays.</p>
<p>建立数据队列，从队列中获取batch_laws和batch_fact，然后sess.run计算图中的某个操作，batch_laws和batch_fact通过feed_dict的方式传入图中，报了上述错误。原因分析：<strong>batch_laws仅仅是tensorflow计算图中定义好的，实际上他并不是一个实际的数据，仅仅是一个Tensor，feed必须是实际的数据。</strong>实际的数据需要通过sess.run()来获得。所以在用sess.run(执行train_op)的时候，需要sess.run(batch_laws)</p>
</li>
<li><p>有关tensorflow各种初始化函数</p>
</li>
</ul>
<ul>
<li><p>对于dunamic_rnn的理解。参考代码中相关的测试代码。在LSTMClassifier中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">layers = [tf.nn.rnn_cell.BasicLSTMCell(num_units=rnn_hidden_size,state_is_tuple=<span class="keyword">True</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">2</span>)]</span><br><span class="line"></span><br><span class="line">stacked_cell=tf.nn.rnn_cell.MultiRNNCell(layers)</span><br></pre></td></tr></table></figure>
<p>假设层数为2，那么dynamic_rnn返回值为outputs与state。outputs很好理解，维度为[batch_size,time_step,hidden_size]。那么如何理解state？<strong>state是最后一个时间步的输出，所以state的形状为[layernum,2，batch_size,hidden_size]，且数据类型为LSTMTuple的数据，是元组state[-1][1]就是先取最后一层，然后再取h，那么综合下来就是取最后一层的h_state</strong>。</p>
</li>
<li><p>多标签分类的one_hot化</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; from sklearn.preprocessing import MultiLabelBinarizer</span><br><span class="line">&gt;&gt;&gt; mlb = MultiLabelBinarizer(classes=[e for e in np.arange(10)])</span><br><span class="line">&gt;&gt;&gt; mlb.fit_transform([(1, 2), (3,)])</span><br></pre></td></tr></table></figure>
<p>在新建mlb的时候可以传入参数classes表示一共有有哪些标签</p>
</li>
<li><p>tensorflow中有关global_step的自增</p>
<p>首先创建变量并初始化很简单，如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">global_step=tf.Variable(<span class="number">0</span>, trainable=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<p>如果要实现global_step自增，需要在定义优化器的时候传入global_step变量才会自增，否则不会。如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_steps)</span><br></pre></td></tr></table></figure>
<p>如果后面部分的global_step=global_steps去掉，global_step的自动加一就会失效。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tf.train.Optimizer.minimize(......global_step=None)</span><br><span class="line">tf.train.Optimizer.compute_gradients()</span><br><span class="line">tf.train.Optimizer.apply_gradients(......，global_step=None)</span><br></pre></td></tr></table></figure>
<p>上面第一个函数是合并了compute_gradients()与apply_gradients()函数，返回为一个优化更新后的var_list。如果global_step非None，该操作还会为global_step做自增操作。</p>
<p>第二个函数对var_list中的变量计算loss的梯度。该函数为函数minimize()的第一部分，返回一个以元组(gradient, variable)组成的列表</p>
<p>第三个函数将计算出的梯度应用到变量上，是函数minimize()的第二部分，返回一个应用指定的梯度的操作Operation，对global_step做自增操作</p>
</li>
<li><p>Tensorflow的模型保存与恢复</p>
<p>meta文件是我们的<strong>计算图结构</strong>文件，其他两个分别保存了变量名和变量值</p>
<p>定义保存目录，并作如下判断：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(ckpt_dir):</span><br><span class="line">    os.makedirs(ckpt_dir)</span><br><span class="line">checkpoint_path=os.path.join(ckpt_dir,<span class="string">"model.ckpt"</span>)</span><br><span class="line">saver.save(sess,checkpoint_path,global_step=global_steps)</span><br></pre></td></tr></table></figure>
<p>这里的global_steps就是我们再定义计算图的时候需要定义的<strong>tf.Variable</strong>。并且该变量需要用在计算图中的Optimizer中，否则不会自增。</p>
<p>除此之外，想控制保存模型的数目，在新建saver的时候，可以有参数max_to_keep选择。</p>
<p>从检查点恢复模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_model</span><span class="params">(sess,FLAGS)</span>:</span></span><br><span class="line">  text_model=Model(FLAGS)</span><br><span class="line">  ckpt=tf.train.get_checkpoint_state(FLAGS.ckpt_dir)</span><br><span class="line">  <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line">    print(<span class="string">"restore old model parameters from %s"</span>%ckpt.model_checkpoint_path)</span><br><span class="line">    text_model.saver.restore(sess,ckpt.model_checkpoint_path)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">"creating new model"</span>)</span><br><span class="line">    sess.run(tf.global_variables_iniializer())</span><br><span class="line">  <span class="keyword">return</span> text_model</span><br></pre></td></tr></table></figure>
<p>当检查点文件存在的时候，从最新检查点恢复模型参数，否则新建model，并执行global_variables_iniializer。</p>
<p><strong>那么有人会问了，假如我们从检查点恢复模型，就不能再执行初始化操作诸如global_variables_iniializer了，那假如这时候我们往模型中添加了一些其他新变量，那么如何执行变量初始化？</strong></p>
<p>重要的事情说三遍：</p>
<p><strong>从检查点恢复模型，不能再执行初始化操作，否则训练的参数值就没意义了。</strong></p>
<p><strong>从检查点恢复模型，不能再执行初始化操作，否则训练的参数值就没意义了。</strong></p>
<p><strong>从检查点恢复模型，不能再执行初始化操作，否则训练的参数值就没意义了。</strong></p>
</li>
<li><p>tf.global_variables_iniializer与tf.local_variables_iniializer区别</p>
<p>tf.global_variables_initializer()添加节点用于初始化所有的变量(<code>GraphKeys.VARIABLES</code>)。返回一个初始化所有全局变量的操作（Op）。<strong>在你构建完整个模型并在会话中加载模型后，运行这个节点。</strong></p>
<p>tf.local_variables_iniializer返回一个初始化所有局部变量的操作（Op）。初始化局部变量（<code>GraphKeys.LOCAL_VARIABLE</code>）。<code>GraphKeys.LOCAL_VARIABLE</code>中的变量指的是被添加入图中，但是未被储存的变量，比如用来记录某些epoch的数量等。</p>
<p>在tensorflow中有一个函数叫做tf.local_variables()，<strong>这个函数会返回局部变量（local variables）。 local_variable() 函数会自动的添加新的变量到构造函数或者get_variable（）自动地把新的变量添加到 graph collection <code>GraphKeys.LOCAL_VARIABLES</code> 中。这个函数返回这个collection中的内容。</strong></p>
</li>
<li><p>为什么要使用变量共享</p>
<p><a href="https://www.cnblogs.com/guoyaohua/p/9476235.html" target="_blank" rel="noopener">https://www.cnblogs.com/guoyaohua/p/9476235.html</a></p>
</li>
<li><p>如何将文件变为可执行脚本，发布出来</p>
<p>利用tf.app.flags.FLAGS，定义一些参数变量和默认值。执行的时候采用tf.app.run()，如果有定义main()函数，直接写tf.app.run()即可。如果没有写main函数，需要在tf.app.run(函数名)写明具体执行什么函数。</p>
</li>
<li><p>Queue读取数据并实现边训练边验证</p>
<p><a href="https://blog.csdn.net/silence1214/article/details/77876552" target="_blank" rel="noopener">https://blog.csdn.net/silence1214/article/details/77876552</a></p>
<p>tensorflow编程中，<strong>假如我们使用placeholder的方法，可以很方便的换输入的数据，通过sess.run的feed_dict参数就能选择传入训练数据还是验证数据。</strong>但假如我们使用queue来读取数据，换输入数据源就不是这么简单的了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">#使用queue方法得到的数据</span><br><span class="line">train_images, train_label = get_batch_train_data(batch_size) </span><br><span class="line">valid_images, valid_label = get_batch_valid_data(batch_size)</span><br><span class="line">def build_graph(x, y):</span><br><span class="line">    #the first layer</span><br><span class="line">    w1 = tf......</span><br><span class="line">    b1 = tf.....</span><br><span class="line">    h1 = tf.nn.relu(tf.matmul(x,w1)+b)...</span><br><span class="line">    #the second layer</span><br><span class="line">    .....</span><br><span class="line">    #the xx layer</span><br><span class="line">    ......</span><br><span class="line">    h = tf.nn.relu(..)</span><br><span class="line">    loss = .....</span><br><span class="line">    accuracy = ...</span><br><span class="line">    train_op = ....</span><br><span class="line"></span><br><span class="line">    return loss, accuracy, train_op</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    ....</span><br><span class="line">    loss, accuracy, train_op = build_graph(train_images, train_label)</span><br><span class="line">    coord = tf.train.Coordinator()</span><br><span class="line">    enqueue_threads = qr.create_threads(sess, coord=coord, start=True)</span><br><span class="line">    try:</span><br><span class="line">      for step in xrange(1000000):</span><br><span class="line">        if coord.should_stop():</span><br><span class="line">          break</span><br><span class="line">        _, acc_str, los_str = sess.run([train_op, accuracy, loss])</span><br><span class="line">        if step % 100 == 0:</span><br><span class="line">        # 这个地方我想加入对验证集合的处理咋办？请看我在代码后面的解释</span><br><span class="line">    except Exception, e:</span><br><span class="line">      coord.request_stop(e)</span><br><span class="line">    finally:</span><br><span class="line">      coord.request_stop()</span><br><span class="line">      coord.join(threads)</span><br></pre></td></tr></table></figure>
<p>一种方法事直接再来一个：loss, accuracy, train_op = build_graph(valid_images, valid_label)。但是，<strong>这是建立了一个新的graph，必须重新initialize所有的变量，而不是之前保存的变量的训练结果。</strong></p>
<p>如何解决，改写graph的定义即可？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">def build_graph():</span><br><span class="line">    is_training = tf.placeholder(dtype=tf.bool, shape=())</span><br><span class="line">    x = tf.cond(is_training, lambda:train_images, lambda:valid_images)</span><br><span class="line">    y = tf.cond(is_training, lambda:train_label, lambda:valid_label)</span><br><span class="line">    #the first layer</span><br><span class="line">    w1 = tf......</span><br><span class="line">    b1 = tf.....</span><br><span class="line">    h1 = tf.nn.relu(tf.matmul(x,w1)+b)...</span><br><span class="line">    #the second layer</span><br><span class="line">    .....</span><br><span class="line">    #the xx layer</span><br><span class="line">    ......</span><br><span class="line">    h = tf.nn.relu(..)</span><br><span class="line"></span><br><span class="line">    loss = .....</span><br><span class="line">    accuracy = ...</span><br><span class="line">    train_op = ....</span><br><span class="line"></span><br><span class="line">    return loss, accuracy, train_op, is_training</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    ....</span><br><span class="line">    loss, accuracy, train_op, is_training = build_graph()</span><br><span class="line">    coord = tf.train.Coordinator()</span><br><span class="line">    enqueue_threads = qr.create_threads(sess, coord=coord, start=True)</span><br><span class="line">    try:</span><br><span class="line">      for step in xrange(1000000):</span><br><span class="line">        if coord.should_stop():</span><br><span class="line">          break</span><br><span class="line">        _, acc_str, los_str = sess.run([train_op, accuracy, loss], &#123;is_training :True&#125;)</span><br><span class="line">        if step % 100 == 0:</span><br><span class="line">            valid_acc_str, valid_los_str = sess.run([accuracy, loss], &#123;is_training:False&#125;)</span><br><span class="line">    except Exception, e:</span><br><span class="line">      coord.request_stop(e)</span><br><span class="line">    finally:</span><br><span class="line">      coord.request_stop()</span><br><span class="line">      coord.join(threads)</span><br></pre></td></tr></table></figure>
<p>这里有一个问题就是：上面验证部分的程序只有针对一个batch的数据进行验证，如果我们想要针对整个验证集合验证模型怎么办？</p>
<ul>
<li><p>法一：设置valid的step为max_valid_step，循环计算max_valid_step多次，但这种情况只能改善上述那种情况，根据设置的max_valid_step不同，有可能会完全遍历验证集，也可能没有将验证集遍历完。</p>
<p>上面这种情况下：在获得valid_batch_data的时候，我们设置string_input_producer的num_epoch为None值，输入队列中的所有文件都被处理后，会将初始化时提供的文件列表的文件全部重新加入队列。这样一来读取valid数据的部分程序肯定不会报OutofRange的Error。<strong>因为我们设置的epoch为None</strong></p>
</li>
<li><p>法二：后面再补充</p>
</li>
</ul>
</li>
<li><p>计算loss和准确率</p>
<p>loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))</p>
<p>注意这里的交叉熵函数不一定要用softmax_cross_entropy_with_logits，多标签分类的时候我们只能选用sigmoid_cross_entropy_with_logits。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))</span><br><span class="line">#求准确率</span><br><span class="line">#tf.cast(correct_prediction, tf.float32) 将布尔型转换为浮点型</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br></pre></td></tr></table></figure>
</li>
<li><p>mnist的多任务多标签问题</p>
<ul>
<li><p>对于单标签：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">correct_class_op = tf.equal(tf.argmax(network.logits_class, 1), tf.argmax(network.golden_class, 1))</span><br><span class="line">    accuracy_class_op = tf.reduce_mean(tf.cast(correct_class_op, tf.float32))</span><br></pre></td></tr></table></figure>
</li>
<li><p>多任务学习：类别预测和属性预测。两个任务的loss加起来作为总的loss，然后用于更新网络参数</p>
</li>
<li><p>多标签准确率计算：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">correct_attrs_op = tf.equal(tf.cast(tf.greater_equal(tf.sigmoid(network.logits_attrs), <span class="number">0.5</span>), tf.int32), tf.cast(network.golden_attrs, tf.int32))</span><br><span class="line"></span><br><span class="line">accuracy_attrs_op = tf.reduce_mean(tf.reduce_min(tf.cast(correct_attrs_op, tf.float32), <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>tf.cast(tf.greater_equal(tf.sigmoid(network.logits_attrs), 0.5), tf.int32)</p>
<p>默认将0.5作为阈值进行0-1标记</p>
<p>tf.reduce_mean(tf.reduce_min(tf.cast(correct_attrs_op, tf.float32), 1))</p>
<p>为什么有一个reduce_min，是因为如果没有完全预测对，如correct_attrs_op为[0,1]，此时reduce_min返回为0，表示预测错误。</p>
</li>
<li><p>不管是多标签还是单标签，再计算loss的时候，都是用的logits来计算的（而不是logits经过one_hot来计算的），只是损失函数不同。</p>
</li>
</ul>
</li>
<li><p>多标签分类的评估标准</p>
<p><a href="https://blog.csdn.net/hzhj2007/article/details/79153647" target="_blank" rel="noopener">https://blog.csdn.net/hzhj2007/article/details/79153647</a></p>
<p><a href="https://blog.csdn.net/wjj5881005/article/details/53389833?utm_source=itdadao&amp;utm_medium=referral" target="_blank" rel="noopener">https://blog.csdn.net/wjj5881005/article/details/53389833?utm_source=itdadao&amp;utm_medium=referral</a></p>
<p><strong>问题在于是不定数量的多标签分类，不知道应该推荐多少个法条</strong>。解决方法：(1)选择一个阈值，对于每个法条是否推荐二分类都有一个阈值，但这个阈值并不是0.5就是最好的，并且每个法条的阈值可能不同，所以需要设定每个法条阈值(2)选择一个数值N，我们只截取排在最前面的N个标签。 </p>
<p>只有知道每个法条是否真的被预测（或者推荐），我们才能建立confusion_matrix矩阵。这样才能计算P、R、F。而每个标签是否被推荐的概率阈值都是不同的，并且不一定是0.5，那么怎么衡量，可参考ROC-AUC曲线。要么就选择截取的方法，选择预测概率值大的前几个。</p>
<ul>
<li><p>汉明损失：表示所有label中错误样本的比例，该值越小表示网络的分类能力越强。</p>
<p><img src="/2018/11/08/Tensorflow编程遇到的问题/汉明.png" alt="汉明"></p>
<p>其中：|D|表示样本总数，|L|表示标签总数，xi和yi分别表示预测结果和ground truth。xor表示异或运算。</p>
</li>
</ul>
</li>
<li><p>tf.nn.top_k函数</p>
<p>返回N维Tensor最低维度的前k个最大的值。返回值为两个Tuple，其中values是前k个最大值的Tuple，indices是各个值对应的下标，默认返回结果是从大到小排序的。</p>
<p>其他类似的函数还有tf.nn.in_top_k()，每个样本的预测结果的前k个最大的数里面是否包含targets预测中的标签，一般都是取1，即取预测最大概率的索引与标签对比。</p>
</li>
<li><p>Tensorflow中tensordot与matmul的区别</p>
<p><a href="https://blog.csdn.net/u012875855/article/details/82850179" target="_blank" rel="noopener">https://blog.csdn.net/u012875855/article/details/82850179</a></p>
</li>
<li><p>Tensorflow的softmax函数默认只针对最后一个维度进行，即一个[batch_size,time_step]的矩阵，是对每一行进行softmax，行与行之间相互独立。</p>
</li>
<li><p>GPU显存占用总结<br><a href="https://zhuanlan.zhihu.com/p/31558973" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/31558973</a></p>
</li>
<li><p>跨卡同步BN</p>
<p><a href="https://zhuanlan.zhihu.com/p/40496177" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/40496177</a></p>
<p>​</p>
<p>​</p>
</li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Tensorflow/" rel="tag"># Tensorflow</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/11/05/ML面试基本问题/" rel="next" title="ML面试基本问题">
                <i class="fa fa-chevron-left"></i> ML面试基本问题
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/11/13/Tensorboard可视化/" rel="prev" title="Tensorboard可视化">
                Tensorboard可视化 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">JinZeng</p>
              <p class="site-description motion-element" itemprop="description">nlper</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">43</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">16</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">16</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://www.zhihu.com/people/jin-ge-ge-21-50-31/activities" target="_blank" title="zhihu">
                      
                        <i class="fa fa-fw fa-globe"></i>zhihu</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Tensorflow编程bug"><span class="nav-number">1.</span> <span class="nav-text">Tensorflow编程bug</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">JinZeng</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
